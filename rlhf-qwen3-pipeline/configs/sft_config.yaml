# Contents of the file: /rlhf-qwen3-pipeline/rlhf-qwen3-pipeline/configs/sft_config.yaml

sft_config:
  model_name: "Qwen/Qwen3-1.7B"
  train_batch_size: 12
  eval_batch_size: 12
  learning_rate: 1e-4
  max_steps: 1000
  gradient_accumulation_steps: 8
  logging_steps: 10
  save_steps: 100
  load_best_model_at_end: true
  evaluation_strategy: "steps"
  eval_steps: 25
  output_dir: "./sft_output"
  weight_decay: 0.01
  warmup_steps: 100
  fp16: true
  mixed_precision: "fp16"
  report_to: "none"