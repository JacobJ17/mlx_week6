# Reward Model Configuration

reward_model:
  model_name: "Qwen/Qwen3-1.7B"
  training_steps: 5000
  batch_size: 32
  learning_rate: 5e-5
  reward_function: "mean_squared_error"
  evaluation_metric: "pearson_correlation"
  save_model_path: "./models/reward_model"
  logging_steps: 100
  early_stopping_patience: 5
  use_cuda: true
  gradient_accumulation_steps: 2
  max_seq_length: 512
  dataset:
    train: "path/to/train_dataset"
    eval: "path/to/eval_dataset"