# PPO Configuration for RLHF Training

ppo_config:
  learning_rate: 3e-5
  batch_size: 32
  num_epochs: 4
  clip_range: 0.2
  gamma: 0.99
  lam: 0.95
  entropy_coef: 0.01
  value_loss_coef: 0.5
  max_grad_norm: 0.5
  log_interval: 10
  save_interval: 1000
  use_gae: true
  reward_scale: 1.0
  rollout_length: 2048
  num_mini_batches: 4
  ppo_epochs: 10
  use_lr_scheduler: true
  lr_scheduler_type: linear
  warmup_steps: 1000
  total_steps: 1000000